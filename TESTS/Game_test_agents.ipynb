{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Game_test_agents.ipynb","provenance":[],"authorship_tag":"ABX9TyN3NO62a7nOH4mlB/neLtiY"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"xGgnCfQyWzUh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"cbec7578-eef3-4e7a-9d5b-f869c7cf7d1a","executionInfo":{"status":"ok","timestamp":1582651315012,"user_tz":-60,"elapsed":149783,"user":{"displayName":"Bruntracer","photoUrl":"","userId":"01660631036721272843"}}},"source":["!pip install git+https://github.com/Shmuma/TextWorld > /dev/null 2>&1\n","!pip install ptan > /dev/null 2>&1\n","!pip3 install torch torchvision > /dev/null 2>&1\n","\n","# Juggling around colab requirement\n","!pip uninstall -y prompt-toolkit > /dev/null 2>&1\n","!pip install prompt-toolkit==1.0.16\n","# DO NOT FORGET to restart runtime as suggested"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting prompt-toolkit==1.0.16\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/a8/a151b6c61718eabe6b4672b6aa760b734989316d62ec1ba4996765e602d4/prompt_toolkit-1.0.16-py3-none-any.whl (244kB)\n","\r\u001b[K     |█▍                              | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 225kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 235kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit==1.0.16) (0.1.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit==1.0.16) (1.12.0)\n","\u001b[31mERROR: textworld 1.1.1 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.16 which is incompatible.\u001b[0m\n","Installing collected packages: prompt-toolkit\n","Successfully installed prompt-toolkit-1.0.16\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["prompt_toolkit"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"nHeGs4JgXss-","colab_type":"text"},"source":["# **Agents**"]},{"cell_type":"markdown","metadata":{"id":"FqLALyN7Yyv3","colab_type":"text"},"source":["##play function"]},{"cell_type":"code","metadata":{"id":"1xIRmVsUX87W","colab_type":"code","colab":{}},"source":["import os\n","from glob import glob\n","\n","import gym\n","import textworld.gym\n","\n","\n","def play(agent, path, max_step=100, nb_episodes=10, verbose=True):\n","    infos_to_request = agent.infos_to_request\n","    infos_to_request.max_score = True  # Needed to normalize the scores.\n","    \n","    gamefiles = [path]\n","    if os.path.isdir(path):\n","        gamefiles = glob(os.path.join(path, \"*.ulx\"))\n","        \n","    env_id = textworld.gym.register_games(gamefiles,\n","                                          request_infos=infos_to_request,\n","                                          max_episode_steps=max_step)\n","    env = gym.make(env_id)  # Create a Gym environment to play the text game.\n","    if verbose:\n","        if os.path.isdir(path):\n","            print(os.path.dirname(path), end=\"\")\n","        else:\n","            print(os.path.basename(path), end=\"\")\n","        \n","    # Collect some statistics: nb_steps, final reward.\n","    avg_moves, avg_scores, avg_norm_scores = [], [], []\n","    for no_episode in range(nb_episodes):\n","        obs, infos = env.reset()  # Start new episode.\n","\n","        score = 0\n","        done = False\n","        nb_moves = 0\n","        while not done:\n","            command = agent.act(obs, score, done, infos)\n","            obs, score, done, infos = env.step(command)\n","            nb_moves += 1\n","        \n","        agent.act(obs, score, done, infos)  # Let the agent know the game is done.\n","                \n","        if verbose:\n","            print(\".\", end=\"\")\n","        avg_moves.append(nb_moves)\n","        avg_scores.append(score)\n","        avg_norm_scores.append(score / infos[\"max_score\"])\n","\n","    env.close()\n","    msg = \"  \\tavg. steps: {:5.1f}; avg. score: {:4.1f} / {}.\"\n","    if verbose:\n","        if os.path.isdir(path):\n","            print(msg.format(np.mean(avg_moves), np.mean(avg_norm_scores), 1))\n","        else:\n","            print(msg.format(np.mean(avg_moves), np.mean(avg_scores), infos[\"max_score\"]))\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fvYS0FwjY-Kv","colab_type":"text"},"source":["##Random Agent"]},{"cell_type":"code","metadata":{"id":"alqxaKChZBz5","colab_type":"code","colab":{}},"source":["from typing import Mapping, Any\n","\n","import numpy as np\n","\n","import textworld.gym\n","\n","\n","class RandomAgent(textworld.gym.Agent):\n","    \"\"\" Agent that randomly selects a command from the admissible ones. \"\"\"\n","    def __init__(self, seed=1234):\n","        self.seed = seed\n","        self.rng = np.random.RandomState(self.seed)\n","\n","    @property\n","    def infos_to_request(self) -> textworld.EnvInfos:\n","        return textworld.EnvInfos(admissible_commands=True)\n","    \n","    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]) -> str:\n","        return self.rng.choice(infos[\"admissible_commands\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LznYyFBXY6Dt","colab_type":"text"},"source":["## Neural agent"]},{"cell_type":"code","metadata":{"id":"-mpjktIKXqau","colab_type":"code","colab":{}},"source":["import re\n","from typing import List, Mapping, Any, Optional\n","from collections import defaultdict\n","\n","import numpy as np\n","\n","import textworld\n","import textworld.gym\n","from textworld import EnvInfos\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","class CommandScorer(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(CommandScorer, self).__init__()\n","        torch.manual_seed(42)  # For reproducibility\n","        self.embedding    = nn.Embedding(input_size, hidden_size)\n","        self.encoder_gru  = nn.GRU(hidden_size, hidden_size)\n","        self.cmd_encoder_gru  = nn.GRU(hidden_size, hidden_size)\n","        self.state_gru    = nn.GRU(hidden_size, hidden_size)\n","        self.hidden_size  = hidden_size\n","        self.state_hidden = torch.zeros(1, 1, hidden_size, device=device)\n","        self.critic       = nn.Linear(hidden_size, 1)\n","        self.att_cmd      = nn.Linear(hidden_size * 2, 1)\n","\n","    def forward(self, obs, commands, **kwargs):\n","        input_length = obs.size(0)\n","        batch_size = obs.size(1)\n","        nb_cmds = commands.size(1)\n","\n","        embedded = self.embedding(obs)\n","        encoder_output, encoder_hidden = self.encoder_gru(embedded)\n","        state_output, state_hidden = self.state_gru(encoder_hidden, self.state_hidden)\n","        self.state_hidden = state_hidden\n","        value = self.critic(state_output)\n","\n","        # Attention network over the commands.\n","        cmds_embedding = self.embedding.forward(commands)\n","        _, cmds_encoding_last_states = self.cmd_encoder_gru.forward(cmds_embedding)  # 1 x cmds x hidden\n","\n","        # Same observed state for all commands.\n","        cmd_selector_input = torch.stack([state_hidden] * nb_cmds, 2)  # 1 x batch x cmds x hidden\n","\n","        # Same command choices for the whole batch.\n","        cmds_encoding_last_states = torch.stack([cmds_encoding_last_states] * batch_size, 1)  # 1 x batch x cmds x hidden\n","\n","        # Concatenate the observed state and command encodings.\n","        cmd_selector_input = torch.cat([cmd_selector_input, cmds_encoding_last_states], dim=-1)\n","\n","        # Compute one score per command.\n","        scores = F.relu(self.att_cmd(cmd_selector_input)).squeeze(-1)  # 1 x Batch x cmds\n","\n","        probs = F.softmax(scores, dim=2)  # 1 x Batch x cmds\n","        index = probs[0].multinomial(num_samples=1).unsqueeze(0) # 1 x batch x indx\n","        return scores, index, value\n","\n","    def reset_hidden(self, batch_size):\n","        self.state_hidden = torch.zeros(1, batch_size, self.hidden_size, device=device)\n","\n","\n","class NeuralAgent:\n","    \"\"\" Simple Neural Agent for playing TextWorld games. \"\"\"\n","    MAX_VOCAB_SIZE = 1000\n","    UPDATE_FREQUENCY = 10\n","    LOG_FREQUENCY = 1000\n","    GAMMA = 0.9\n","    \n","    def __init__(self) -> None:\n","        self._initialized = False\n","        self._epsiode_has_started = False\n","        self.id2word = [\"<PAD>\", \"<UNK>\"]\n","        self.word2id = {w: i for i, w in enumerate(self.id2word)}\n","        \n","        self.model = CommandScorer(input_size=self.MAX_VOCAB_SIZE, hidden_size=128)\n","        self.optimizer = optim.Adam(self.model.parameters(), 0.00003)\n","        \n","        self.mode = \"test\"\n","    \n","    def train(self):\n","        self.mode = \"train\"\n","        self.stats = {\"max\": defaultdict(list), \"mean\": defaultdict(list)}\n","        self.transitions = []\n","        self.model.reset_hidden(1)\n","        self.last_score = 0\n","        self.no_train_step = 0\n","    \n","    def test(self):\n","        self.mode = \"test\"\n","        self.model.reset_hidden(1)\n","        \n","    @property\n","    def infos_to_request(self) -> EnvInfos:\n","        return EnvInfos(description=True, inventory=True, admissible_commands=True,\n","                        has_won=True, has_lost=True)\n","    \n","    def _get_word_id(self, word):\n","        if word not in self.word2id:\n","            if len(self.word2id) >= self.MAX_VOCAB_SIZE:\n","                return self.word2id[\"<UNK>\"]\n","            \n","            self.id2word.append(word)\n","            self.word2id[word] = len(self.word2id)\n","            \n","        return self.word2id[word]\n","            \n","    def _tokenize(self, text):\n","        # Simple tokenizer: strip out all non-alphabetic characters.\n","        text = re.sub(\"[^a-zA-Z0-9\\- ]\", \" \", text)\n","        word_ids = list(map(self._get_word_id, text.split()))\n","        return word_ids\n","\n","    def _process(self, texts):\n","        texts = list(map(self._tokenize, texts))\n","        max_len = max(len(l) for l in texts)\n","        padded = np.ones((len(texts), max_len)) * self.word2id[\"<PAD>\"]\n","\n","        for i, text in enumerate(texts):\n","            padded[i, :len(text)] = text\n","\n","        padded_tensor = torch.from_numpy(padded).type(torch.long).to(device)\n","        padded_tensor = padded_tensor.permute(1, 0) # Batch x Seq => Seq x Batch\n","        return padded_tensor\n","      \n","    def _discount_rewards(self, last_values):\n","        returns, advantages = [], []\n","        R = last_values.data\n","        for t in reversed(range(len(self.transitions))):\n","            rewards, _, _, values = self.transitions[t]\n","            R = rewards + self.GAMMA * R\n","            adv = R - values\n","            returns.append(R)\n","            advantages.append(adv)\n","            \n","        return returns[::-1], advantages[::-1]\n","\n","    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]) -> Optional[str]:\n","        \n","        # Build agent's observation: feedback + look + inventory.\n","        input_ = \"{}\\n{}\\n{}\".format(obs, infos[\"description\"], infos[\"inventory\"])\n","        \n","        # Tokenize and pad the input and the commands to chose from.\n","        input_tensor = self._process([input_])\n","        commands_tensor = self._process(infos[\"admissible_commands\"])\n","        \n","        # Get our next action and value prediction.\n","        outputs, indexes, values = self.model(input_tensor, commands_tensor)\n","        action = infos[\"admissible_commands\"][indexes[0]]\n","        \n","        if self.mode == \"test\":\n","            if done:\n","                self.model.reset_hidden(1)\n","            return action\n","        \n","        self.no_train_step += 1\n","        \n","        if self.transitions:\n","            reward = score - self.last_score  # Reward is the gain/loss in score.\n","            self.last_score = score\n","            if infos[\"has_won\"]:\n","                reward += 100\n","            if infos[\"has_lost\"]:\n","                reward -= 100\n","                \n","            self.transitions[-1][0] = reward  # Update reward information.\n","        \n","        self.stats[\"max\"][\"score\"].append(score)\n","        if self.no_train_step % self.UPDATE_FREQUENCY == 0:\n","            # Update model\n","            returns, advantages = self._discount_rewards(values)\n","            \n","            loss = 0\n","            for transition, ret, advantage in zip(self.transitions, returns, advantages):\n","                reward, indexes_, outputs_, values_ = transition\n","                \n","                advantage        = advantage.detach() # Block gradients flow here.\n","                probs            = F.softmax(outputs_, dim=2)\n","                log_probs        = torch.log(probs)\n","                log_action_probs = log_probs.gather(2, indexes_)\n","                policy_loss      = (-log_action_probs * advantage).sum()\n","                value_loss       = (.5 * (values_ - ret) ** 2.).sum()\n","                entropy     = (-probs * log_probs).sum()\n","                loss += policy_loss + 0.5 * value_loss - 0.1 * entropy\n","                \n","                self.stats[\"mean\"][\"reward\"].append(reward)\n","                self.stats[\"mean\"][\"policy\"].append(policy_loss.item())\n","                self.stats[\"mean\"][\"value\"].append(value_loss.item())\n","                self.stats[\"mean\"][\"entropy\"].append(entropy.item())\n","                self.stats[\"mean\"][\"confidence\"].append(torch.exp(log_action_probs).item())\n","            \n","            if self.no_train_step % self.LOG_FREQUENCY == 0:\n","                msg = \"{}. \".format(self.no_train_step)\n","                msg += \"  \".join(\"{}: {:.3f}\".format(k, np.mean(v)) for k, v in self.stats[\"mean\"].items())\n","                msg += \"  \" + \"  \".join(\"{}: {}\".format(k, np.max(v)) for k, v in self.stats[\"max\"].items())\n","                msg += \"  vocab: {}\".format(len(self.id2word))\n","                print(msg)\n","                self.stats = {\"max\": defaultdict(list), \"mean\": defaultdict(list)}\n","            \n","            loss.backward()\n","            nn.utils.clip_grad_norm_(self.model.parameters(), 40)\n","            self.optimizer.step()\n","            self.optimizer.zero_grad()\n","        \n","            self.transitions = []\n","            self.model.reset_hidden(1)\n","        else:\n","            # Keep information about transitions for Truncated Backpropagation Through Time.\n","            self.transitions.append([None, indexes, outputs, values])  # Reward will be set on the next call\n","        \n","        if done:\n","            self.last_score = 0  # Will be starting a new episode. Reset the last score.\n","        \n","        return action"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fVwIHicyX0v3","colab_type":"text"},"source":["##Load"]},{"cell_type":"code","metadata":{"id":"xmoGTdDYYEGW","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":142},"outputId":"b0aaffcb-d50b-4cb7-bbfc-36602f0a6c2c","executionInfo":{"status":"ok","timestamp":1582651523145,"user_tz":-60,"elapsed":71263,"user":{"displayName":"Bruntracer","photoUrl":"","userId":"01660631036721272843"}}},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-c99d88cf-61bb-4133-bf4b-9ad387db760f\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-c99d88cf-61bb-4133-bf4b-9ad387db760f\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving etsit.ulx to etsit.ulx\n","Saving etsit.json to etsit.json\n","Saving agent0.ag to agent0.ag\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eSyU40n1XjNN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7701b976-64f8-457f-e9b0-3fae361f0cc4","executionInfo":{"status":"ok","timestamp":1582651549103,"user_tz":-60,"elapsed":568,"user":{"displayName":"Bruntracer","photoUrl":"","userId":"01660631036721272843"}}},"source":["import pickle\n","# Step 2\n","with open('agent0.ag', 'rb') as config_dictionary_file:\n"," \n","    # Step 3\n","    agent_loaded = pickle.load(config_dictionary_file)\n"," \n","    # After config_dictionary is read from file\n","    print(agent_loaded)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["<__main__.NeuralAgent object at 0x7f3f8b33a198>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S1-aIrD_YXjt","colab_type":"text"},"source":["## Test Games"]},{"cell_type":"code","metadata":{"id":"qjJjtSiFYW0U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"7be32210-ac8d-4078-a003-6c9f8ca7e5a6","executionInfo":{"status":"ok","timestamp":1582651763771,"user_tz":-60,"elapsed":23392,"user":{"displayName":"Bruntracer","photoUrl":"","userId":"01660631036721272843"}}},"source":["play(RandomAgent(), \"etsit.ulx\")\n","play(agent_loaded, \"etsit.ulx\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["etsit.ulx..........  \tavg. steps: 100.0; avg. score:  0.0 / 1.\n","etsit.ulx..........  \tavg. steps:  91.4; avg. score:  0.3 / 1.\n"],"name":"stdout"}]}]}